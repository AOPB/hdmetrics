R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
R = 10000
U = runif(R)
mean(log(U))
mean(log(U)^2)
qnorm(.05)
mean(log(U)) + qnorm(.025)*sqrt(var(log(U))/R)
qnorm(.025)
mean(log(U)) + qnorm(.025)*sqrt(var(log(U))/R)
mean(log(U)) + qnorm(.975)*sqrt(var(log(U))/R)
117-35
82/15
82-25
57/15
57/4
96-35
61-25
36/4
12*4
96-48
48/2
151/9
3/13
3/19
13/19
1/19
2/19
16+68+5+11
16+68
300/16
249+80
355*(1-0.035)
355*(1-0.035)+15
355*.965
355*.965 + 15- 328.56
### Set working directory
setwd("//ulysse/users/JL.HOUR/1A_These/B. ENSAE Classes/Cours3A/hdmetrics")
rm(list=ls())
set.seed(03101989)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
### Load user-defined functions
source("functions/LassoFISTA.R")
source("functions/ATE.R")
Penn = as.data.frame(read.table("packages\DMLonGitHub-master\penn_jae.dat", header=T ));
### Pennsylvania Bonus Data
Penn = as.data.frame(read.table("packages/DMLonGitHub-master/penn_jae.dat", header=T ))
index = (Penn$tg==0) | (Penn$tg==4)
sum(index)
data = Penn[index,]
data$tg[data$tg==4] = 1
data$tg
### Pennsylvania Bonus Data
Penn = as.data.frame(read.table("packages/DMLonGitHub-master/penn_jae.dat", header=T ))
########################### Sample Construction ######################
index = (Penn$tg==0) | (Penn$tg==4) # Only keep treatment=4 and controls
data = Penn[index,]
data$tg[data$tg==4] = 1
data$dep = as.factor(data$dep)
data$inuidur1 = log(data$inuidur1)
Y = data[,"inuidur1"] # Outcome
D = data[,"tg"] # Treatment
X = data[,c("female","black","othrace","dep","q2","q3","q4","q5","q6","agelt35","agegt54","durable","lusd","husd")] # Covariates
source("functions/LassoFISTA.R")
source("functions/LogitLasso.R")
K = 5
n = length(Y)
split = runif(n)
cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))
### Double ML Heterogeneous Treatment Effect
### Set working directory
setwd("//ulysse/users/JL.HOUR/1A_These/B. ENSAE Classes/Cours3A/hdmetrics")
rm(list=ls())
set.seed(03101989)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
### Load user-defined functions
source("functions/LassoFISTA.R")
source("functions/LogitLasso.R")
source("functions/ATE.R")
### Pennsylvania Bonus Data
Penn = as.data.frame(read.table("packages/DMLonGitHub-master/penn_jae.dat", header=T ))
########################### Sample Construction ######################
index = (Penn$tg==0) | (Penn$tg==4) # Only keep treatment=4 and controls
data = Penn[index,]
data$tg[data$tg==4] = 1
data$dep = as.factor(data$dep)
data$inuidur1 = log(data$inuidur1)
Y = data[,"inuidur1"] # Outcome
D = data[,"tg"] # Treatment
X = data[,c("female","black","othrace","dep","q2","q3","q4","q5","q6","agelt35","agegt54","durable","lusd","husd")] # Covariates
K = 5
n = length(Y)
split = runif(n)
cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))
### 1. Lasso-style
theta = vector(length=K)
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
treatfit = LogitLasso(D[NIk],X[NIk])
k=1
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk])
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
X = as.matrix(data[,c("female","black","othrace","dep","q2","q3","q4","q5","q6","agelt35","agegt54","durable","lusd","husd")]) # Covariates
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
summarize(data$dep)
summary(data$dep)
### Double ML Heterogeneous Treatment Effect
### Set working directory
setwd("//ulysse/users/JL.HOUR/1A_These/B. ENSAE Classes/Cours3A/hdmetrics")
rm(list=ls())
set.seed(03101989)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
### Load user-defined functions
source("functions/LassoFISTA.R")
source("functions/LogitLasso.R")
source("functions/ATE.R")
### Pennsylvania Bonus Data
Penn = as.data.frame(read.table("packages/DMLonGitHub-master/penn_jae.dat", header=T ))
########################### Sample Construction ######################
index = (Penn$tg==0) | (Penn$tg==4) # Only keep treatment=4 and controls
data = Penn[index,]
data$tg[data$tg==4] = 1
data[,"dep1"] = data$dep==1
data[,"dep2"] = data$dep==2
data$inuidur1 = log(data$inuidur1)
Y = data[,"inuidur1"] # Outcome
D = data[,"tg"] # Treatment
X = as.matrix(data[,c("female","black","othrace","dep1","dep2","q2","q3","q4","q5","q6","agelt35","agegt54","durable","lusd","husd")]) # Covariates
K = 5
n = length(Y)
split = runif(n)
cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))
head(X)
### 1. Lasso-style
theta = vector(length=K)
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
k=
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
k=1
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
treatfit
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
mhat = X[Ik,] %*% treatfit$betaLasso
mhat = 1/(1+exp(-X[Ik,] %*% treatfit$betaLasso))
mhat
sum(d)
sum(D)
mean(D)
tapply(mhat,D)
### Double ML Heterogeneous Treatment Effect
### Set working directory
setwd("//ulysse/users/JL.HOUR/1A_These/B. ENSAE Classes/Cours3A/hdmetrics")
rm(list=ls())
set.seed(03101989)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
### Load user-defined functions
source("functions/LassoFISTA.R")
source("functions/LogitLasso.R")
source("functions/ATE.R")
### Pennsylvania Bonus Data
Penn = as.data.frame(read.table("packages/DMLonGitHub-master/penn_jae.dat", header=T ))
########################### Sample Construction ######################
index = (Penn$tg==0) | (Penn$tg==4) # Only keep treatment=4 and controls
data = Penn[index,]
data$tg[data$tg==4] = 1
data[,"dep1"] = data$dep==1
data[,"dep2"] = data$dep==2
data$inuidur1 = log(data$inuidur1)
Y = data[,"inuidur1"] # Outcome
D = data[,"tg"] # Treatment
X = as.matrix(data[,c("female","black","othrace","dep1","dep2","q2","q3","q4","q5","q6","agelt35","agegt54","durable","lusd","husd")]) # Covariates
K = 5
n = length(Y)
X = cbind(rep(1,n),X)
split = runif(n)
cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))
### 1. Lasso-style
theta = vector(length=K)
k=1
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,])
mhat = 1/(1+exp(-X[Ik,] %*% treatfit$betaLasso))
treatfit
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,],c=.2)
mhat = 1/(1+exp(-X[Ik,] %*% treatfit$betaLasso))
treatfit
sd(mhat)
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,],c=.2,PostLasso=T)
mhat = 1/(1+exp(-X[Ik,] %*% treatfit$betaPL))
sd(mhat)
treatfit
g = .1/log(max(ncol(X),sum(Ik)))
lambdastar = 2.2*qnorm(1-.5*g/p)/sqrt(sum(Ik)) # Lasso penalty level
g = .1/log(max(ncol(X),sum(Ik)))
lambdastar = 2.2*qnorm(1-.5*g/ncol(Ik))/sqrt(sum(Ik)) # Lasso penalty level
outcomefit = LassoFISTA(y=y[D==0,NIk],X=X[D==0,NIk,],nopen=c(1),lambda=lambdastar) # Do not penalize the constant
D==0 && NIk
D[NIk]
sum(NIk)
n
sum(D[NIk])
outcomefit0 = LassoFISTA(y=y[D==0,NIk],X=X[D[NIk]==0,],nopen=c(1),lambda=lambdastar) # Do not penalize the constant
outcomefit0 = LassoFISTA(y=y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=lambdastar) # Do not penalize the constant
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=lambdastar) # Do not penalize the constant
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=as.matrix(X[D[NIk]==0,]),nopen=c(1),lambda=lambdastar) # Do not penalize the constant
MM = X[D[NIk]==0,]
dim(MM)
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=4*lambdastar) # Do not penalize the constant
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=0*lambdastar) # Do not penalize the constant
MM = X[D[NIk]==0,]
dim(MM)
dim(Y[D[NIk]==0])
length(Y[D[NIk]==0])
betaInit=rep(0,ncol(MM))
W=rep(1,nrow(MM))
W = as.vector(W)
u = Y[D[NIk]==0]
u = sqrt(W)*u
MM = sweep(MM,MARGIN=1,sqrt(W),`*`)
dim(MM)
eta = 1/max(2*eigen(t(MM)%*%MM)$values/nrow(MM))
theta = 1
thetaO = theta
beta = betaInit
v = beta
cv = 0
k = 0
k = k+1
thetaO = theta
theta = (1+sqrt(1+4*thetaO^2))/2
delta = (1-thetaO)/theta
betaO = beta
beta = prox(v - eta*LeastSqgrad(v,u,MM), lambda*eta,nopen)
beta = prox(v - eta*LeastSqgrad(v,u,MM), 1*eta,nopen)
beta = prox(v - eta*LeastSqgrad(v,u,MM), 1*eta,c(1))
beta
v = (1-delta)*beta + delta*betaO
LassoObj(beta,u,MM,lambda,nopen)
LassoObj(beta,u,MM,lambda,c(1))
LassoObj(beta,u,MM,1,c(1))
### Double ML Heterogeneous Treatment Effect
### Set working directory
setwd("//ulysse/users/JL.HOUR/1A_These/B. ENSAE Classes/Cours3A/hdmetrics")
rm(list=ls())
set.seed(03101989)
### 0. Settings
### Load packages
library("ggplot2")
library("gridExtra")
library("MASS")
### Load user-defined functions
source("functions/LassoFISTA.R")
source("functions/LogitLasso.R")
source("functions/ATE.R")
### Pennsylvania Bonus Data
Penn = as.data.frame(read.table("packages/DMLonGitHub-master/penn_jae.dat", header=T ))
########################### Sample Construction ######################
index = (Penn$tg==0) | (Penn$tg==4) # Only keep treatment=4 and controls
data = Penn[index,]
data$tg[data$tg==4] = 1
data[,"dep1"] = data$dep==1
data[,"dep2"] = data$dep==2
data$inuidur1 = log(data$inuidur1)
Y = data[,"inuidur1"] # Outcome
D = data[,"tg"] # Treatment
X = as.matrix(data[,c("female","black","othrace","dep1","dep2","q2","q3","q4","q5","q6","agelt35","agegt54","durable","lusd","husd")]) # Covariates
K = 5
n = length(Y)
X = cbind(rep(1,n),X)
split = runif(n)
cvgroup = as.numeric(cut(split,quantile(split,probs = seq(0, 1, 1/K)),include.lowest = T))
theta = vector(length=K)
k=1
Ik = cvgroup==k # Separate the sample
NIk = cvgroup!=k
# A. Propensity Score
treatfit = LogitLasso(D[NIk],X[NIk,],c=.2,PostLasso=T)
mhat = 1/(1+exp(-X[Ik,] %*% treatfit$betaPL))
# B. Selection on Y_0
g = .1/log(max(ncol(X),sum(Ik)))
lambdastar = 2.2*qnorm(1-.5*g/ncol(Ik))/sqrt(sum(Ik)) # Lasso penalty level
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=0*lambdastar) # Do not penalize the constant
# B. Selection on Y_0
g = .1/log(max(ncol(X),sum(Ik)))
lambdastar = 2.2*qnorm(1-.5*g/ncol(Ik))/sqrt(sum(Ik)) # Lasso penalty level
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=0*lambdastar) # Do not penalize the constant
dim(X)
mu
dim(mu)
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=0*lambdastar) # Do not penalize the constant
outcomefit0 = LassoFISTA(y=Y[D[NIk]==0],X=X[D[NIk]==0,],nopen=c(1),lambda=0*lambdastar) # Do not penalize the constant
